\chapter{Resultados}
\label{Resultados}
\markboth{}{}


En este capítulo vamos a analizar la efectividad de los modelos propuestos.
El experimento se realizó en CPU(Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz)
 
\section{Red inicial}
\label{Redinit}


Con los hiperparámetros obtenidos en el Capítulo~\ref{Red Neuronal}, se definieron las muestras de entrenamiento 
($10^6$ elementos), validación ($10^5$ elementos) y test ($10^5$ elementos). Se crearon dos muestras, una amplia y una estrecha. La muestra amplia es para entrenamiento y validación y la muestra estrecha para test. En el Cuadro~\ref{cu:Himu} se define el ambiente de las muestras, y para generar la muestra se utilizó el algoritmo~\ref{muestras}.


\begin{table}[!htbp]
\begin{center}
\caption{Hiperparámetros de la Muestra}
\label{cu:Himu}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Parámetros & muestra amplia  &  muestra estrecha   \\ \hline
  & precio ratio($S_0/K$) & $[0.4, 1.6]$ & $[0.5, 1.5]$   \\ \cline{2-4} 
 Entrada & Tiempo de madurez($\tau$) &  $[0.2, 1.1]$ & $[0.3, 0.95]$   \\ \cline{2-4} 
  & volatilidad($\sigma$) &  $[0.01, 1]$ & $[0.02, 0.9]$  \\ \cline{2-4} 
  & Tasa libre de riesgo($r$) &  $[0.02, 0.1]$ & $[0.03, 0.08]$ \\ \hline
 Salida & Precio de Call($c/K$) &  $(0, 0.9)$ & $(0, 0.73)$ \\ \hline
\end{tabular}
\end{center}
\end{table}

Una vez obtenida la muestra, la entrada de la red fueron las uplas $\{c/K, S_0/K, r, \tau\}$ y la salida 
$\{\sigma\}$. Se entrenó la red durante $1000$ épocas utilizando la muestra amplia y los hiperparámetros del obtenidos Capítulo anterior. 

Una vez entrenada la red, en el Cuadro~\ref{cu:errorpr} y en las Figuras~\ref{fig:PreApr} y~\ref{fig:PreEpr} se pueden observar los resultados una vez realizado el entrenamiento de la red, donde $S(\sigma)$ es la desviación estándar de la diferencia entre la volatilidad implícita y la volatilidad estimada por la red.


\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_n.png}
    \caption{Predicción muestra amplia.}
    \label{fig:PreApr}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_n.png}
    \caption{Predicción muestra estrecha.}
    \label{fig:PreEpr}
  \end{minipage}
\end{figure}

\begin{table}[!htbp]
\begin{center}
\caption{Error de predicción en el test de la red original.}
\label{cu:errorpr}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $3.21 \times 10^{-4}$ & $6.09 \times 10^{-3}$ & $9.30$ & $0.996031$  \\ \hline
Muestra Estrecha & $1.47 \times 10^{-4}$ &  $4.07 \times 10^{-3}$ & $5.46$ & $0.997714$  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


\section{Optimización}
\label{sec:opti}

Ya tenemos los hiperparámetros óptimos del capítulo anterior, entonces vamos a definir la muestra de entrenamiento
($10^6$ elementos), validación ($10^5$ elementos) y test ($10^5$ elementos). Crearemos 2 muestras, una amplia y una estrecha. A diferencia de la muestra de la sección anterior, en esta se va a modificar utilizando la fórmula (\ref{form:opti}) del capítulo anterior. En el cuadro~\ref{cu:muestraent} se define el ambiente de la muestra, y para generar las muestras se usa el algoritmo~\ref{muestras}.

\begin{table}[!htbp]
\begin{center}
\caption{Hiperparámetros de la Muestra}
\label{cu:muestraent}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Parámetros & muestra amplia  &  muestra estrecha   \\ \hline
  & precio ratio($S_0/K$) & $[0.4, 1.6]$ & $[0.5, 1.5]$   \\ \cline{2-4} 
 Entrada & Tiempo de madurez($\tau$) &  $[0.2, 1.1]$ & $[0.3, 0.95]$   \\ \cline{2-4} 
  & volatilidad($\sigma$) &  $[0.01, 1]$ & $[0.02, 0.9]$  \\ \cline{2-4} 
  & Tasa libre de riesgo($r$) &  $[0.02, 0.1]$ & $[0.03, 0.08]$ \\ \hline
 Salida & Precio de Call($\ln(\tilde{c}/{K})$) &  $[-16.12,-0.94]$ & $[-16.12,-0.94]$ \\ \hline
\end{tabular}
\end{center}
\end{table}

Una vez obtenida la muestra, la entrada de la red será $\{\ln(\tilde{c}/K, S_0/K, r, \tau\}$ y la salida $\{\sigma\}$. Vamos a entrenar la red durante 1000 épocas.

Una vez entrenada la red, en el Cuadro~\ref{cu:resultopti} y en las Figuras~\ref{fig:resultoptiA} y \ref{fig:resultoptiE} se pueden observar los resultados, donde $S(\sigma)$ es la desviación estándar de la diferencia entre la volatilidad implícita y la volatilidad estimada por la red.


\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_log_mil.png}
    \caption{Predicción muestra amplia.}
    \label{fig:resultoptiA}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_log_mil.png}
    \caption{Predicción muestra estrecha.}
    \label{fig:resultoptiE}
  \end{minipage}
\end{figure}

\begin{table}[!htbp]
\begin{center}
\caption{Error de predicción en el test de la red optimizada.}
\label{cu:resultopti}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $6.24\times10^{-8}$ & $1.92\times10^{-4}$ & $0.059$ & $0.999999104$  \\ \hline
Muestra Estrecha & $5.58\times10^{-8}$ &  $ 1.84\times10^{-4}$ & $0.062$ & $0.999999020$  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


\subsection{Cambio en función de decrecimiento de la Tasa de Aprendizaje}

Observando la Figura~\ref{Smith} podemos concluir que el entrenamiento de la red con una tasa de aprendizaje menor a $10^{-7}$ prácticamente no actualizaría los pesos, entonces si queremos hacer mas épocas en el entrenamiento de la red, con el algoritmo que usamos en la sección anterior tendríamos en la época 3000 una tasa de aprendizaje aproximado de 
$1.87\times10^{-17}$, y en la época 1000 la tasa de aprendizaje aproximado sería de $2.65\times10^{-8}$. Una posible solución a este problema es modificar los hiperparámetros óptimos aumentando el $base\_lr$, aumentar el $decay$, y aumentar el $epoch\_drop$, para que la tasa de aprendizaje descienda mas lentamente. Otra solución sería cuando la tasa de aprendizaje sea menor a un umbral, aumentar el $base\_lr$. El umbral puede ser variable.

El algoritmo~\ref{al:decay} muestra el método de decrecimiento de la tasa de aprendizaje que utilizaremos.


\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\ResetInOut{output}
\Input{epoch}
\Output{lrate}
 i := 0\;
 step := floor((1+epoch)/10)\;
 lrate := 0.0005 * pow(0.9, step)\;
 \While{lrate $< 10^{-(6+i)}$}{
  lrate := 100*lrate\;
  i = i + 0.5\;
 }
 return\;
 \caption{Step Decay Modificado}
 \label{al:decay}
\end{algorithm}


La Figura~\ref{StepDvsModi} muestra la comparación entre el step decay usado anteriormente y el step decay modificado.

\begin{figure}[t!]
  \includegraphics[width=16cm%, height=10cm
  ]{imagenes/comparacion_step_1000}
  \caption{Step Decay contra Step Decay Modificado}
  \label{StepDvsModi}
\end{figure}

Las Figuras~\ref{aprend1000} y~\ref{aprend3000} muestran el tasa de aprendizaje resultante con los diferentes algoritmos.

\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{lr_1000.png}
    \caption{Tasa de aprendizaje sobre 1000 épocas.}
    \label{aprend1000}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{lr_3000.png}
    \caption{Tasa de aprendizaje sobre 3000 épocas.}
    \label{aprend3000}
  \end{minipage}
\end{figure}

Luego vamos a entrenar la red durante $3000$ épocas usando step decay modificado. Una vez entrenada la red 
en el Cuadro~\ref{cu:erroropti} y en las Figuras~\ref{resultamplia},~\ref{resultestrecha} se observan los resultados, donde $S(\sigma)$ es la desviación estándar de la diferencia entre la volatilidad implícita y la volatilidad estimada por la red.

\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_w_log_3mil.png}
    \caption{Predicción muestra amplia.}
    \label{resultamplia}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Predic_n_log_3mil.png}
    \caption{Predicción muestra estrecha.}
    \label{resultestrecha}
  \end{minipage}
\end{figure} 

\begin{table}[!htbp]
\begin{center}
\caption{Error de predicción en el test de la red final.}
\label{cu:erroropti}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Muestra Amplia  & $4.67\times10^{-8}$ & $1.66\times10^{-4}$ & $0.0515$ & $0.999999329$  \\ \hline
Muestra Estrecha & $4.02\times10^{-8}$ &  $ 1.57\times10^{-4}$ & $0.0526$ & $0.999999295$  \\ \hline
  
\end{tabular}
\end{center}
\end{table}

En el Cuadro~\ref{comparacionModelos} se compara el rendimiento de cada red neuronal implementada por su error y por su desviación estándar, se puede observar que cuando se modifica la entrada de la red en la sección~\ref{sec:opti} las métricas de la red mejoran considerablemente (4 ordenes en el ECM), y cuando se modifica la función de decrecimiento de la tasa de aprendizaje mejora aproximadamente un 25\% comparando su ECM.

\begin{table}[!htbp]
\begin{center}
\caption{Error de predicción en el test de la red final.}
\label{comparacionModelos}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$ & Desvió estándar\\ \hline
Red inicial  & $3.21 \times 10^{-4}$ & $6.09 \times 10^{-3}$ & $9.30$ & $0.996031$ & $0.017664868$\\ \hline
Red optimizada & $6.24\times10^{-8}$ & $1.92\times10^{-4}$ & $0.059$ & $0.999999104$ & $0.0002491482$\\ \hline
Red definitiva & $4.67\times10^{-8}$ & $1.66\times10^{-4}$ & $0.0515$ & $0.999999329$ & $0.000215171$\\ \hline
  
\end{tabular}
\end{center}
\end{table}


\section{Métodos Numéricos}


\subsection{Problemas Numéricos}
\label{sub:Problemas}

En la muestra amplia definida en la sección~\ref{Redinit} hay aproximadamente un 0.05\% de casos que no cumplen con la condición $g(a)g(b) < 0$, 
para $a \to 0$ y $b \to \infty$, donde $g$ es la función~\ref{funciong} anteriormente.

El problema radica en el cálculo de la fórmula de Black-Scholes definida en la ecuación~\ref{eq:black},
básicamente en la distribución de probabilidad acumulada $\Phi(d)$. Por definición $\Phi(d) < 1$, $\forall d \in \mathbb{R}$. 
Pero Python usa aritmética de punto flotante IEEE-754~\cite{IEEE}, donde su precisión es $2^{-56}$,
dando así una precisión aproximada de $15,95$ dígitos decimales. 
Luego usando la función de Scipy para el cálculo de la distribución normal acumulada definida en la referencia~\cite{Normal}, 
obtenemos $\Phi(n) = 1$, para $n > 8.3$.
%
Volviendo a la fórmula de Black-Scholes, si bien sabemos que $\Phi(d_1) > \Phi(d_2)$, ya que $\sigma,T > 0$, 
pero hay casos en que el extremo inferior definido para aplicar el método de bisección (o Brent), se obtiene 
$\Phi(d_1) = \Phi(d_2)$ por el problema de precisión, ocasionando el error antes mencionado.

Luego el problema está en la cantidad de posibles números representables en un dado rango. 
El formato se escribe con un significando que tiene un bit entero implícito de valor 1 (excepto para los números especiales). 
Con los 52 bits de la mantisa, la precisión total es por lo tanto de 53 bits (es decir de $53 \,\log_{10}(2) \approx 15.955$ 
que se redondea a 16 dígitos decimales). El exponente de este formato está sesgado o desplazado en $1023$ unidades, 
ya que como el máximo valor representado por $11$ bits es  $2^{11}-1 = 2047$, es la mitad de este rango la que representa 
exponentes positivos y la otra, exponentes negativos~\cite{IEEE}. Podemos observar esto en la Figura~\ref{reprebinaria}.
Lo expuesto permite ver que hay $2^{52}$ números de punto flotante entre $2^n$ y $2^{n+1}$ para todo $n$ entero en $[-1023, 1022]$.

\begin{figure}[t!]
  \centering
  \includegraphics[clip,width=0.9\textwidth]{imagenes/precision}
  \caption{Estructura de un número en formato de coma flotante de doble precisión}
  \label{reprebinaria}
\end{figure}


%\subsection{Caso en Particular}

Por ejemplo, consideremos un caso en particular, tomando los valores del Cuadro~\ref{params} se puede observar en la Figura~\ref{fig:gin1} que $g(n) >= 0$ para $n \in [ 0.01, 1 ]$, por lo tanto no se puede aplicar el método de bisección 
(o Brent).



\begin{table}[!htbp]
\centering
\begin{tabular}{|ll|}
\hline
$c$: & $5.983489610184446$  \\ 
$S$: & $15.752756180327959$  \\             % \cline{2-4} 
$k$: & $10$   \\ % \cline{2-4} 
$r$: & $0.09010364215460305$ \\               % \cline{2-4} 
$T$: & $0.2590760904347537$  \\ \hline
\end{tabular}
\caption{Parámetros que no cumplen la pre-condición de los métodos numéricos}
\label{params}
\end{table}



\vspace{5mm}

Luego si $\sigma = 0.01$ (extremo inferior del intervalo), se obtiene,
%
$\Phi(d_1) = 1$, $\Phi(d_2) = 1$
%
y $g(0.01) = 1.7763568394002505\times10^{-15}$.
%
Pero si se evalúa la función de distribución normal acumulada utilizando la volatilidad implícita ($\sigma = 0.11928197090875538$), se obtiene 
%
$\Phi(d_1) = 0.9999999999999986$ (Figuras~\ref{fig:d1},~\ref{fig:d1c}), $\Phi(d_2) = 0.9999999999999982$ 
y
$g(0.11928197091) = 0$, se contradice la propiedad de monotonía creciente. 

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.9\textwidth]{g}
  \caption{Función $g$.}
  \label{fig:gin1}
\end{figure}

\begin{figure}[]
   \centering
   %\begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=0.9\textwidth]{norm1.png}
    \caption{$\Phi(d_1)$.}
    \label{fig:d1}
\end{figure}
\begin{figure}
   %\end{minipage}
   %\hfill
   %\begin{minipage}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{norm1_c.png}
    \caption{$\Phi(d_1)$.}
    \label{fig:d1c}
  %\end{minipage}
\end{figure}


\subsection{Precisi\'on M\'etodos Num\'ericos} 


En la sección~\ref{sub:Problemas} vimos que hay casos en los que no se puede aplicar los métodos numéricos, exceptuando esos casos, vamos a analizar su precisión. Ademas se vio que lo máximo que podemos aspirar es un error absoluto de 
$2^{-56}$. Ahora vamos a analizar si en la práctica, la tolerancia de los métodos corresponden con los resultados obtenidos de aplicar los mismos. En el método de Brent utilizamos el de la biblioteca Scipy~\cite{Brentq}.

%En el cuadro 6.6 se muestran los resultados.

\begin{table}[!htbp]
\begin{center}
\caption{Error Brent y Bisección}
\label{metodosnum}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & ECM & EAM  &  EPAM & $R^2$  \\ \hline
Bisección  & $1.10\times10^{-8}$ & $2.89\times10^{-6}$ & $0.00469$ & $0.99999986$  \\ \hline
Brent & $8.17\times10^{-6}$ &  $ 9.18\times10^{-5}$ & $0.35894$ & $0.99989551$  \\ \hline
  
\end{tabular}
\end{center}
\end{table}


%\subsection{Peso de la Volatilidad sobre el precio de la opción}

Observando el Cuadro~\ref{metodosnum}, el error absoluto medio del método de bisección es $2.89\times10^{-6}$ y de Brent es $ 9.18\times10^{-5}$, siendo la tolerancia $2^{-56}$, esto es por el problema de precisión y el impacto que tiene la volatilidad sobre el precio de la opción (derivada de la fórmula de Black-Scholes sobre $\sigma$) utilizando la fórmula de Black-Scholes~\ref{eq:black}. En la Figura~\ref{ratiovscall}, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes ratios ($S/K$), se puede observar que mientras más diferencia hay entre
$S_0$ y K la volatilidad tiene menos impacto sobre el precio en especial en los casos OTM y en las volatilidades cercanas a $0$. Luego en la Figura~\ref{interesvscall}, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes tasas de interés, se observa prácticamente un desplazamiento.
Por último en la Figura~\ref{Tvscall}, que compara el precio de la opción con respecto a la variación de volatilidad, utilizando diferentes tiempos de madurez, se puede observa que mientras los contratos sean más largos la volatilidad tiene un mayor impacto sobre el precio.

\begin{figure}[t!]
  \centering
  \includegraphics[width=16cm%, height=8cm
  ]{imagenes/ratio_v_call}
  \caption{Volatilidad implícita contra precio call con distintos ratios}
  \label{ratiovscall}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=16cm%, height=6cm
  ]{imagenes/interes_v_call}
  \caption{Volatilidad implícita contra precio call con distintas tasas de interés}
  \label{interesvscall}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=16cm%, height=6cm
  ]{imagenes/T_v_call}
  \caption{Volatilidad implícita contra precio call con distintos tiempos de madurez}
  \label{Tvscall}
\end{figure}

Ahora bien observando los gráficos podemos concluir que la volatilidad tiene menos impacto en los contratos cortos(en nuestro ambiente), en OTM y con volatilidades menores a 0.2, pero en la practica los casos con mas error son ITM
con $\Phi_1(\sigma)$ y $\Phi_2(\sigma)$ cercanos a 1.

Esto se debe a la densidad de puntos flotantes visto en la sección anterior. Luego como el ancho de 11 bits del exponente permite la representación de números en el rango comprendido entre 
$2^{-1023}$ y $2^{1023}$ ($10^{-308}$ y $10^{308}$ aproximado). Esto nos permite concluir que hay aproximadamente la misma cantidad de números representables entre $10^{-307}$ y $10^{-306}$ que en $0.1$ y $1$, osea que su densidad es mayor cuando tiende a 0 (Observar Figura~\ref{Densidad10}). Por lo tanto los $\Phi_1(\sigma)$ y $\Phi_2(\sigma)$
cercanos a 0 en OTM van a tener mas precisión aunque el peso de la volatilidad sobre el precio de la opción sea menor.


\begin{figure}[t!]
  \centering
  \includegraphics[width=14cm%, height=8cm
  ]{imagenes/precision_g}
  \caption{Densidad de números representables en rango de $10^{-5}$ entre 0.1 y 1}
  \label{Densidad10}
\end{figure}





\section{Tiempo de Ejecución y Robustez}

Una vez entrenada la red (Fue calculado sobre GPU(GeForce GTX 1080/PCIe/SSE2), RAM(15.6 GiB). La búsqueda de hiperpámetros en un tiempo $10.08$ horas, la búsqueda del algoritmo de la tasa de aprendizaje fue $11.72$ horas y entrenamiento de la red $3000$ épocas fue $8.83$ horas), vamos a observar el tiempo ejecución de evaluación de la misma sobre una muestra de tamaño $10^{5}$. Ademas el tiempo de ejecución de los métodos de Brent y bisección sobre la misma muestra en una CPU(Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz).

También analizaremos su robustez, esto sería, si para todo elemento de la muestra el modelo genera una salida.

En el Cuadro~\ref{fig:robustez} se observan el tiempo de ejecución y la Robustez. 

\begin{table}[!htbp]
\begin{center}
\caption{Robustez y Tiempo de Ejecución}
\label{fig:robustez}
\begin{tabular}{|l|l|l|l|l|}
\hline
 & Red Neuronal & Método de Brent  &  Método de Bisección  \\ \hline
Tiempo de Ejecución(s)  & $7.34$  & $157.05$ & $318.31$   \\ \hline
Robustez & Si  &  No & No \\ \hline
  
\end{tabular}
\end{center}
\end{table}